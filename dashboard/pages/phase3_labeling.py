import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import numpy as np
from datetime import datetime, timedelta
import sys
import os
from pathlib import Path
import logging

# Configurar rutas del proyecto
project_root = Path(r"c:\dev\trading_embedding")
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / 'src'))

try:
    from data.data_manager import DataManager
    from ml.labeling import (
        WyckoffHeuristicEngine,
        WyckoffScoringSystem,
        DatasetManager,
        LabeledSample
    )
except ImportError as e:
    st.error(f"Error importando componentes de ML: {e}")
    st.stop()

def show_phase3_labeling_page(data_manager):
    """P√°gina principal del sistema de etiquetado Wyckoff - Fase 3 (Redise√±ada)."""
    
    st.title("üè∑Ô∏è Fase 3: Etiquetado Inteligente de Patrones Wyckoff")
    
    # Introducci√≥n clara y visual
    st.markdown("""
    <div style="background: linear-gradient(90deg, #667eea 0%, #764ba2 100%); padding: 20px; border-radius: 10px; color: white; margin-bottom: 20px;">
        <h3>üéØ ¬øQu√© hace la Fase 3?</h3>
        <p><strong>Convierte datos de trading en conocimiento para IA:</strong></p>
        <ul>
            <li>üîç <strong>Detecta autom√°ticamente</strong> patrones Wyckoff en gr√°ficos de precios</li>
            <li>üìä <strong>Eval√∫a la calidad</strong> de cada patr√≥n encontrado</li>
            <li>üè∑Ô∏è <strong>Etiqueta manualmente</strong> para crear datasets de entrenamiento</li>
            <li>ü§ñ <strong>Prepara datos</strong> para entrenar modelos de IA</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)
    
    # Flujo paso a paso visual
    st.markdown("""
    ### üîÑ Flujo de Trabajo Simplificado
    """)
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown("""
        <div style="text-align: center; padding: 20px; border: 3px solid #2E7D32; border-radius: 12px; background: linear-gradient(135deg, #E8F5E8 0%, #F1F8E9 100%); box-shadow: 0 4px 8px rgba(46, 125, 50, 0.2);">
            <h4 style="color: #1B5E20; font-weight: bold; margin-bottom: 8px;">1Ô∏è‚É£ DETECTAR</h4>
            <p style="color: #2E7D32; font-weight: 500; margin: 0;">Busca patrones Wyckoff autom√°ticamente</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div style="text-align: center; padding: 20px; border: 3px solid #1565C0; border-radius: 12px; background: linear-gradient(135deg, #E3F2FD 0%, #E8F4FD 100%); box-shadow: 0 4px 8px rgba(21, 101, 192, 0.2);">
            <h4 style="color: #0D47A1; font-weight: bold; margin-bottom: 8px;">2Ô∏è‚É£ EVALUAR</h4>
            <p style="color: #1565C0; font-weight: 500; margin: 0;">Punt√∫a la calidad de cada patr√≥n</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div style="text-align: center; padding: 20px; border: 3px solid #E65100; border-radius: 12px; background: linear-gradient(135deg, #FFF3E0 0%, #FFF8F0 100%); box-shadow: 0 4px 8px rgba(230, 81, 0, 0.2);">
            <h4 style="color: #BF360C; font-weight: bold; margin-bottom: 8px;">3Ô∏è‚É£ ETIQUETAR</h4>
            <p style="color: #E65100; font-weight: 500; margin: 0;">Confirma o corrige manualmente</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        st.markdown("""
        <div style="text-align: center; padding: 20px; border: 3px solid #6A1B9A; border-radius: 12px; background: linear-gradient(135deg, #F3E5F5 0%, #F8F5F9 100%); box-shadow: 0 4px 8px rgba(106, 27, 154, 0.2);">
            <h4 style="color: #4A148C; font-weight: bold; margin-bottom: 8px;">4Ô∏è‚É£ ENTRENAR</h4>
            <p style="color: #6A1B9A; font-weight: 500; margin: 0;">Crea datasets para IA</p>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # Configuraci√≥n simplificada en la parte superior
    st.markdown("### ‚öôÔ∏è Configuraci√≥n R√°pida")
    
    col_config1, col_config2, col_config3 = st.columns(3)
    
    with col_config1:
        symbol = st.selectbox(
            "üìà Criptomoneda",
            ["BTCUSDT", "ETHUSDT", "ADAUSDT", "DOTUSDT", "LINKUSDT"],
            index=0,
            help="Selecciona el par de trading a analizar"
        )
    
    with col_config2:
        timeframe = st.selectbox(
            "‚è∞ Temporalidad",
            ["1h", "4h", "1d", "1w"],
            index=2,
            help="Intervalo de tiempo de las velas"
        )
    
    with col_config3:
        days_back = st.slider(
            "üìÖ Per√≠odo (d√≠as)",
            min_value=7,
            max_value=360,
            value=30,
            help="Cu√°ntos d√≠as hacia atr√°s analizar"
        )
    
    # Tabs redise√±ados con mejor UX
    tab1, tab2, tab3 = st.tabs([
        "üîç Paso 1: Detectar Patrones",
        "üè∑Ô∏è Paso 2: Etiquetar y Validar", 
        "üìä Paso 3: Gestionar Datasets"
    ])
    
    with tab1:
        show_pattern_detection_redesigned(data_manager, symbol, timeframe, days_back)
    
    with tab2:
        show_labeling_interface_redesigned(data_manager, symbol, timeframe, days_back)
    
    with tab3:
        show_dataset_management_redesigned(data_manager)

def show_pattern_detection_redesigned(data_manager, symbol, timeframe, days_back):
    """Interfaz redise√±ada para detecci√≥n de patrones - Paso 1."""
    
    st.markdown("""
    <div style="background: #2d5a2d; padding: 20px; border-radius: 12px; border-left: 6px solid #4CAF50; box-shadow: 0 4px 8px rgba(0,0,0,0.2); color: #ffffff;">
        <h4 style="color: #ffffff; margin-bottom: 15px; font-weight: 600;">üîç Paso 1: Detecci√≥n Autom√°tica de Patrones</h4>
        <p style="color: #e8f5e8; margin-bottom: 15px; font-size: 16px;">El sistema analiza los datos de precios y volumen para identificar autom√°ticamente patrones Wyckoff como:</p>
        <ul style="color: #e8f5e8; font-size: 15px; line-height: 1.6;">
            <li><strong style="color: #ffffff;">Acumulaci√≥n:</strong> Zonas donde grandes inversores compran discretamente</li>
            <li><strong style="color: #ffffff;">Distribuci√≥n:</strong> Zonas donde grandes inversores venden discretamente</li>
            <li><strong style="color: #ffffff;">Re-acumulaci√≥n:</strong> Pausas en tendencias alcistas</li>
            <li><strong style="color: #ffffff;">Re-distribuci√≥n:</strong> Pausas en tendencias bajistas</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)
    
    # Configuraci√≥n avanzada en expander
    with st.expander("‚öôÔ∏è Configuraci√≥n Avanzada de Detecci√≥n"):
        col1, col2 = st.columns(2)
        
        with col1:
            min_confidence = st.slider(
                "üéØ Confianza M√≠nima",
                min_value=0.1,
                max_value=1.0,
                value=0.6,
                step=0.1,
                help="Solo mostrar patrones con esta confianza o mayor"
            )
            
            max_signals = st.number_input(
                "üìä M√°ximo de Se√±ales",
                min_value=5,
                max_value=50,
                value=15,
                help="Limitar el n√∫mero de patrones a mostrar"
            )
        
        with col2:
            volume_weight = st.slider(
                "üìà Peso del Volumen",
                min_value=0.1,
                max_value=2.0,
                value=1.0,
                step=0.1,
                help="Importancia del volumen en la detecci√≥n"
            )
            
            pattern_types = st.multiselect(
                "üé® Tipos de Patrones",
                ["Acumulaci√≥n", "Distribuci√≥n", "Re-acumulaci√≥n", "Re-distribuci√≥n"],
                default=["Acumulaci√≥n", "Distribuci√≥n"],
                help="Selecciona qu√© tipos de patrones detectar"
            )
    
    # Bot√≥n principal de detecci√≥n
    if st.button("üöÄ Iniciar Detecci√≥n de Patrones", type="primary", use_container_width=True):
        with st.spinner("üîç Analizando datos y detectando patrones Wyckoff..."):
            try:
                # Mostrar progreso
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # Paso 1: Obtener datos
                status_text.text("üìä Obteniendo datos hist√≥ricos...")
                progress_bar.progress(20)
                
                end_time = datetime.now()
                start_time = end_time - timedelta(days=days_back)
                
                df = data_manager.get_data(
                    symbol=symbol,
                    interval=timeframe,
                    start_time=start_time,
                    end_time=end_time
                )
                
                if df.empty:
                    st.error("‚ùå No se pudieron obtener datos para el an√°lisis")
                    return
                
                # Paso 2: Inicializar motor de detecci√≥n
                status_text.text("ü§ñ Inicializando motor de detecci√≥n...")
                progress_bar.progress(40)
                
                heuristic_engine = WyckoffHeuristicEngine()
                
                # Paso 3: Detectar patrones
                status_text.text("üîç Detectando patrones Wyckoff...")
                progress_bar.progress(60)
                
                signals = heuristic_engine.analyze_pattern(df)
                
                # Paso 4: Filtrar resultados
                status_text.text("üéØ Filtrando y clasificando resultados...")
                progress_bar.progress(80)
                
                filtered_signals = [
                    s for s in signals 
                    if s.confidence >= min_confidence
                ][:max_signals]
                
                progress_bar.progress(100)
                status_text.text("‚úÖ ¬°Detecci√≥n completada!")
                
                # Mostrar resultados de forma clara
                st.markdown("---")
                st.markdown("### üìä Resultados de la Detecci√≥n")
                
                # M√©tricas principales
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric(
                        "üéØ Patrones Encontrados",
                        len(filtered_signals),
                        delta=f"de {len(signals)} totales"
                    )
                
                with col2:
                    avg_confidence = np.mean([s.confidence for s in filtered_signals]) if filtered_signals else 0
                    st.metric(
                        "üìà Confianza Promedio",
                        f"{avg_confidence:.1%}",
                        delta=f"Min: {min_confidence:.1%}"
                    )
                
                with col3:
                    st.metric(
                        "üìÖ Per√≠odo Analizado",
                        f"{days_back} d√≠as",
                        delta=f"{len(df)} velas"
                    )
                
                with col4:
                    price_range = df['high'].max() - df['low'].min()
                    st.metric(
                        "üí∞ Rango de Precios",
                        f"${price_range:.2f}",
                        delta=f"{symbol}"
                    )
                
                if filtered_signals:
                    # Gr√°fico interactivo mejorado
                    st.markdown("### üìà Gr√°fico de Precios con Patrones Detectados")
                    
                    fig = create_enhanced_price_chart(df, filtered_signals, symbol)
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # Tabla de se√±ales mejorada
                    st.markdown("### üìã Detalle de Patrones Detectados")
                    
                    signals_data = []
                    for i, signal in enumerate(filtered_signals, 1):
                        # Determinar color seg√∫n el tipo de patr√≥n
                        phase_color = {
                            'accumulation': 'üü¢',
                            'distribution': 'üî¥',
                            'reaccumulation': 'üü°',
                            'redistribution': 'üü†'
                        }.get(signal.phase.value.lower(), '‚ö™')
                        
                        description = getattr(signal, 'description', 'Patr√≥n Wyckoff detectado')
                        
                        signals_data.append({
                            "#": i,
                            "üïê Fecha y Hora": signal.timestamp.strftime("%d/%m/%Y %H:%M"),
                            "üé® Tipo": f"{phase_color} {signal.phase.value.title()}",
                            "üí∞ Precio": f"${signal.price:.2f}",
                            "üéØ Confianza": f"{signal.confidence:.1%}",
                            "üìù Descripci√≥n": description[:60] + "..." if len(description) > 60 else description
                        })
                    
                    signals_df = pd.DataFrame(signals_data)
                    st.dataframe(signals_df, use_container_width=True, hide_index=True)
                    
                    # An√°lisis estad√≠stico
                    st.markdown("### üìä An√°lisis Estad√≠stico")
                    
                    col_stats1, col_stats2 = st.columns(2)
                    
                    with col_stats1:
                        # Distribuci√≥n por tipos
                        phase_counts = {}
                        for signal in filtered_signals:
                            phase = signal.phase.value.title()
                            phase_counts[phase] = phase_counts.get(phase, 0) + 1
                        
                        if phase_counts:
                            fig_pie = px.pie(
                                values=list(phase_counts.values()),
                                names=list(phase_counts.keys()),
                                title="Distribuci√≥n por Tipo de Patr√≥n",
                                color_discrete_sequence=px.colors.qualitative.Set3
                            )
                            fig_pie.update_traces(textposition='inside', textinfo='percent+label')
                            st.plotly_chart(fig_pie, use_container_width=True)
                    
                    with col_stats2:
                        # Distribuci√≥n de confianza
                        confidence_values = [s.confidence for s in filtered_signals]
                        fig_hist = px.histogram(
                            x=confidence_values,
                            nbins=8,
                            title="Distribuci√≥n de Niveles de Confianza",
                            labels={"x": "Confianza", "y": "Cantidad de Patrones"},
                            color_discrete_sequence=['#4CAF50']
                        )
                        fig_hist.update_layout(showlegend=False)
                        st.plotly_chart(fig_hist, use_container_width=True)
                    
                    # Guardar resultados para siguiente paso
                    st.session_state['detected_patterns'] = filtered_signals
                    st.session_state['analysis_data'] = df
                    st.session_state['analysis_symbol'] = symbol
                    st.session_state['analysis_timeframe'] = timeframe
                    
                    st.success("‚úÖ ¬°Patrones detectados exitosamente! Ahora puedes ir al **Paso 2** para etiquetarlos.")
                    
                else:
                    st.warning("‚ö†Ô∏è No se encontraron patrones que cumplan con los criterios especificados. Intenta reducir la confianza m√≠nima o aumentar el per√≠odo de an√°lisis.")
                    
            except Exception as e:
                st.error(f"‚ùå Error durante la detecci√≥n: {str(e)}")
                st.exception(e)

def create_enhanced_price_chart(df, signals, symbol):
    """Crea un gr√°fico de precios mejorado con patrones Wyckoff."""
    
    fig = make_subplots(
        rows=2, cols=1,
        shared_xaxes=True,
        vertical_spacing=0.1,
        subplot_titles=(f'Precio de {symbol}', 'Volumen'),
        row_width=[0.7, 0.3]
    )
    
    # Gr√°fico de velas
    fig.add_trace(
        go.Candlestick(
            x=df.index,
            open=df['open'],
            high=df['high'],
            low=df['low'],
            close=df['close'],
            name='Precio',
            increasing_line_color='#26a69a',
            decreasing_line_color='#ef5350'
        ),
        row=1, col=1
    )
    
    # Agregar se√±ales con colores distintivos
    colors = {
        'accumulation': '#4CAF50',
        'distribution': '#f44336',
        'reaccumulation': '#FF9800',
        'redistribution': '#9C27B0'
    }
    
    symbols_map = {
        'accumulation': 'triangle-up',
        'distribution': 'triangle-down',
        'reaccumulation': 'circle',
        'redistribution': 'square'
    }
    
    for signal in signals:
        phase_key = signal.phase.value.lower()
        color = colors.get(phase_key, '#757575')
        symbol_shape = symbols_map.get(phase_key, 'circle')
        
        fig.add_trace(
            go.Scatter(
                x=[signal.timestamp],
                y=[signal.price],
                mode='markers',
                marker=dict(
                    symbol=symbol_shape,
                    size=15,
                    color=color,
                    line=dict(width=2, color='white')
                ),
                name=f'{signal.phase.value.title()} ({signal.confidence:.1%})',
                hovertemplate=f'<b>{signal.phase.value.title()}</b><br>' +
                             f'Precio: ${signal.price:.2f}<br>' +
                             f'Confianza: {signal.confidence:.1%}<br>' +
                             f'Fecha: {signal.timestamp.strftime("%d/%m/%Y %H:%M")}<extra></extra>'
            ),
            row=1, col=1
        )
    
    # Gr√°fico de volumen
    colors_volume = ['#26a69a' if close >= open else '#ef5350' 
                    for close, open in zip(df['close'], df['open'])]
    
    fig.add_trace(
        go.Bar(
            x=df.index,
            y=df['volume'],
            name='Volumen',
            marker_color=colors_volume,
            opacity=0.7
        ),
        row=2, col=1
    )
    
    # Configuraci√≥n del layout
    fig.update_layout(
        title=f'An√°lisis de Patrones Wyckoff - {symbol}',
        xaxis_title='Fecha',
        yaxis_title='Precio (USD)',
        yaxis2_title='Volumen',
        height=700,
        showlegend=True,
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        )
    )
    
    fig.update_xaxes(rangeslider_visible=False)
    
    return fig

def show_labeling_interface_redesigned(data_manager, symbol, timeframe, days_back):
    """Interfaz redise√±ada para etiquetado manual - Paso 2."""
    
    st.markdown("""
    <div style="background: #1a365d; padding: 20px; border-radius: 12px; border-left: 6px solid #2196F3; box-shadow: 0 4px 8px rgba(0,0,0,0.2); color: #ffffff;">
        <h4 style="color: #ffffff; margin-bottom: 15px; font-weight: 600;">üè∑Ô∏è Paso 2: Etiquetado y Validaci√≥n Manual</h4>
        <p style="color: #e3f2fd; margin-bottom: 15px; font-size: 16px;">Revisa y valida los patrones detectados autom√°ticamente. Tu experiencia como trader es crucial para:</p>
        <ul style="color: #e3f2fd; font-size: 15px; line-height: 1.6;">
            <li><strong style="color: #ffffff;">Confirmar patrones v√°lidos:</strong> Marca como correctos los patrones bien identificados</li>
            <li><strong style="color: #ffffff;">Rechazar falsos positivos:</strong> Descarta patrones incorrectos</li>
            <li><strong style="color: #ffffff;">Ajustar clasificaciones:</strong> Corrige el tipo de patr√≥n si es necesario</li>
            <li><strong style="color: #ffffff;">A√±adir contexto:</strong> Agrega notas y observaciones importantes</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)
    
    # Verificar si hay patrones detectados
    if 'detected_patterns' not in st.session_state or not st.session_state['detected_patterns']:
        st.warning("‚ö†Ô∏è No hay patrones detectados. Ve al **Paso 1** para detectar patrones primero.")
        return
    
    patterns = st.session_state['detected_patterns']
    df = st.session_state.get('analysis_data')
    
    st.markdown(f"### üìä Etiquetando {len(patterns)} patrones detectados")
    
    # Inicializar estado de etiquetado si no existe
    if 'labeling_results' not in st.session_state:
        st.session_state['labeling_results'] = {}
    
    # Selector de patr√≥n para revisar
    pattern_options = []
    for i, pattern in enumerate(patterns):
        status = st.session_state['labeling_results'].get(i, {}).get('status', '‚è≥ Pendiente')
        pattern_options.append(
            f"{i+1}. {pattern.phase.value.title()} - {pattern.timestamp.strftime('%d/%m %H:%M')} - {status}"
        )
    
    selected_idx = st.selectbox(
        "üéØ Selecciona un patr√≥n para revisar:",
        range(len(patterns)),
        format_func=lambda x: pattern_options[x]
    )
    
    if selected_idx is not None:
        current_pattern = patterns[selected_idx]
        
        # Mostrar detalles del patr√≥n actual
        st.markdown("---")
        st.markdown(f"### üîç Revisando Patr√≥n #{selected_idx + 1}")
        
        col_info1, col_info2, col_info3 = st.columns(3)
        
        with col_info1:
            st.metric("üé® Tipo Detectado", current_pattern.phase.value.title())
            st.metric("üí∞ Precio", f"${current_pattern.price:.2f}")
        
        with col_info2:
            st.metric("üéØ Confianza IA", f"{current_pattern.confidence:.1%}")
            st.metric("üïê Timestamp", current_pattern.timestamp.strftime("%d/%m/%Y %H:%M"))
        
        with col_info3:
            # Calcular puntuaci√≥n si est√° disponible
            try:
                scoring_system = WyckoffScoringSystem()
                # Obtener ventana de datos alrededor del patr√≥n
                signal_idx = df.index.get_loc(current_pattern.timestamp)
                window_start = max(0, signal_idx - 20)
                window_end = min(len(df), signal_idx + 21)
                window_data = df.iloc[window_start:window_end].copy()
                
                if not window_data.empty:
                    score = scoring_system.score_signal(current_pattern, window_data, signal_idx - window_start)
                    st.metric("‚≠ê Puntuaci√≥n IA", f"{score.overall_score:.1f}/5")
                    st.metric("üìä Categor√≠a", score.category)
                else:
                    st.metric("‚≠ê Puntuaci√≥n IA", "N/A")
                    st.metric("üìä Categor√≠a", "N/A")
            except:
                st.metric("‚≠ê Puntuaci√≥n IA", "N/A")
                st.metric("üìä Categor√≠a", "N/A")
        
        # Gr√°fico enfocado en el patr√≥n actual
        st.markdown("### üìà Vista Detallada del Patr√≥n")
        
        # Crear gr√°fico centrado en el patr√≥n
        if df is not None:
            pattern_time = current_pattern.timestamp
            
            # Obtener ventana de tiempo alrededor del patr√≥n
            try:
                pattern_idx = df.index.get_loc(pattern_time)
                start_idx = max(0, pattern_idx - 50)
                end_idx = min(len(df), pattern_idx + 50)
                
                focused_df = df.iloc[start_idx:end_idx]
                focused_patterns = [current_pattern]  # Solo mostrar el patr√≥n actual
                
                fig_focused = create_enhanced_price_chart(focused_df, focused_patterns, symbol)
                fig_focused.update_layout(title=f"Patr√≥n #{selected_idx + 1}: {current_pattern.phase.value.title()}")
                st.plotly_chart(fig_focused, use_container_width=True)
                
            except Exception as e:
                st.error(f"Error creando gr√°fico: {e}")
        
        # Interfaz de etiquetado
        st.markdown("### ‚úÖ Validaci√≥n Manual")
        
        col_label1, col_label2 = st.columns(2)
        
        with col_label1:
            # Estado del patr√≥n
            current_status = st.session_state['labeling_results'].get(selected_idx, {}).get('status', 'pending')
            
            status = st.radio(
                "üéØ ¬øEs este patr√≥n v√°lido?",
                options=['valid', 'invalid', 'uncertain'],
                format_func=lambda x: {
                    'valid': '‚úÖ V√°lido - Patr√≥n correcto',
                    'invalid': '‚ùå Inv√°lido - Falso positivo', 
                    'uncertain': '‚ùì Incierto - Necesita m√°s an√°lisis'
                }[x],
                index=['valid', 'invalid', 'uncertain'].index(current_status) if current_status in ['valid', 'invalid', 'uncertain'] else 0
            )
            
            # Tipo de patr√≥n corregido
            current_type = st.session_state['labeling_results'].get(selected_idx, {}).get('corrected_type', current_pattern.phase.value)
            
            corrected_type = st.selectbox(
                "üé® Tipo de patr√≥n correcto:",
                options=['accumulation', 'distribution', 'reaccumulation', 'redistribution'],
                format_func=lambda x: {
                    'accumulation': 'üü¢ Acumulaci√≥n',
                    'distribution': 'üî¥ Distribuci√≥n',
                    'reaccumulation': 'üü° Re-acumulaci√≥n',
                    'redistribution': 'üü† Re-distribuci√≥n'
                }[x],
                index=['accumulation', 'distribution', 'reaccumulation', 'redistribution'].index(current_type) if current_type in ['accumulation', 'distribution', 'reaccumulation', 'redistribution'] else 0
            )
        
        with col_label2:
            # Confianza del trader
            trader_confidence = st.slider(
                "üéØ Tu nivel de confianza:",
                min_value=0.0,
                max_value=1.0,
                value=st.session_state['labeling_results'].get(selected_idx, {}).get('trader_confidence', 0.5),
                step=0.1,
                help="¬øQu√© tan seguro est√°s de tu evaluaci√≥n?"
            )
            
            # Calidad del patr√≥n
            quality_score = st.slider(
                "‚≠ê Calidad del patr√≥n (1-5):",
                min_value=1,
                max_value=5,
                value=st.session_state['labeling_results'].get(selected_idx, {}).get('quality_score', 3),
                help="Califica la claridad y fuerza del patr√≥n"
            )
        
        # Notas del trader
        notes = st.text_area(
            "üìù Notas y observaciones:",
            value=st.session_state['labeling_results'].get(selected_idx, {}).get('notes', ''),
            placeholder="Agrega cualquier observaci√≥n importante sobre este patr√≥n...",
            height=100
        )
        
        # Botones de acci√≥n
        col_btn1, col_btn2, col_btn3 = st.columns(3)
        
        with col_btn1:
            if st.button("üíæ Guardar Etiqueta", type="primary", use_container_width=True):
                # Guardar resultado del etiquetado
                st.session_state['labeling_results'][selected_idx] = {
                    'status': status,
                    'corrected_type': corrected_type,
                    'trader_confidence': trader_confidence,
                    'quality_score': quality_score,
                    'notes': notes,
                    'timestamp': datetime.now(),
                    'original_pattern': current_pattern
                }
                st.success("‚úÖ Etiqueta guardada exitosamente!")
        
        with col_btn2:
            if st.button("‚è≠Ô∏è Siguiente Patr√≥n", use_container_width=True):
                if selected_idx < len(patterns) - 1:
                    st.rerun()
        
        with col_btn3:
            if st.button("üìä Ver Progreso", use_container_width=True):
                show_labeling_progress(patterns)

def show_labeling_progress(patterns):
    """Muestra el progreso del etiquetado."""
    
    st.markdown("### üìä Progreso del Etiquetado")
    
    total_patterns = len(patterns)
    labeled_count = len(st.session_state.get('labeling_results', {}))
    
    progress = labeled_count / total_patterns if total_patterns > 0 else 0
    
    st.progress(progress)
    st.write(f"**{labeled_count}/{total_patterns}** patrones etiquetados ({progress:.1%} completado)")
    
    if labeled_count > 0:
        # Estad√≠sticas de etiquetado
        results = st.session_state['labeling_results']
        
        valid_count = sum(1 for r in results.values() if r['status'] == 'valid')
        invalid_count = sum(1 for r in results.values() if r['status'] == 'invalid')
        uncertain_count = sum(1 for r in results.values() if r['status'] == 'uncertain')
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("‚úÖ V√°lidos", valid_count)
        with col2:
            st.metric("‚ùå Inv√°lidos", invalid_count)
        with col3:
            st.metric("‚ùì Inciertos", uncertain_count)

def show_dataset_management_redesigned(data_manager):
    """Interfaz redise√±ada para gesti√≥n de datasets - Paso 3."""
    
    st.markdown("""
    <div style="background: #4a1a4a; padding: 20px; border-radius: 12px; border-left: 6px solid #9C27B0; box-shadow: 0 4px 8px rgba(0,0,0,0.2); color: #ffffff;">
        <h4 style="color: #ffffff; margin-bottom: 15px; font-weight: 600;">üìä Paso 3: Gesti√≥n de Datasets de Entrenamiento</h4>
        <p style="color: #f3e5f5; margin-bottom: 15px; font-size: 16px;">Convierte tus etiquetas validadas en datasets listos para entrenar modelos de IA. Aqu√≠ puedes:</p>
        <ul style="color: #f3e5f5; font-size: 15px; line-height: 1.6;">
            <li><strong style="color: #ffffff;">Crear datasets:</strong> Genera conjuntos de datos estructurados desde tus etiquetas</li>
            <li><strong style="color: #ffffff;">Exportar datos:</strong> Descarga en formatos compatibles con frameworks de ML</li>
            <li><strong style="color: #ffffff;">Gestionar versiones:</strong> Mant√©n control de diferentes versiones de tus datasets</li>
            <li><strong style="color: #ffffff;">An√°lisis de calidad:</strong> Revisa estad√≠sticas y distribuci√≥n de tus datos</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)
    
    # Verificar si hay etiquetas disponibles
    labeling_results = st.session_state.get('labeling_results', {})
    
    if not labeling_results:
        st.warning("‚ö†Ô∏è No hay etiquetas disponibles. Ve al **Paso 2** para etiquetar patrones primero.")
        return
    
    # Estad√≠sticas de etiquetas disponibles
    st.markdown("### üìà Resumen de Etiquetas Disponibles")
    
    valid_labels = {k: v for k, v in labeling_results.items() if v['status'] == 'valid'}
    total_labels = len(labeling_results)
    valid_count = len(valid_labels)
    
    col_stats1, col_stats2, col_stats3, col_stats4 = st.columns(4)
    
    with col_stats1:
        st.metric("üìù Total Etiquetas", total_labels)
    
    with col_stats2:
        st.metric("‚úÖ Etiquetas V√°lidas", valid_count)
    
    with col_stats3:
        quality_avg = np.mean([v['quality_score'] for v in valid_labels.values()]) if valid_labels else 0
        st.metric("‚≠ê Calidad Promedio", f"{quality_avg:.1f}/5")
    
    with col_stats4:
        confidence_avg = np.mean([v['trader_confidence'] for v in valid_labels.values()]) if valid_labels else 0
        st.metric("üéØ Confianza Promedio", f"{confidence_avg:.1%}")
    
    if valid_count == 0:
        st.warning("‚ö†Ô∏è No hay etiquetas v√°lidas para crear datasets. Marca algunos patrones como v√°lidos en el Paso 2.")
        return
    
    # Distribuci√≥n por tipo de patr√≥n
    st.markdown("### üìä Distribuci√≥n de Patrones V√°lidos")
    
    pattern_counts = {}
    for label_data in valid_labels.values():
        pattern_type = label_data['corrected_type']
        pattern_counts[pattern_type] = pattern_counts.get(pattern_type, 0) + 1
    
    if pattern_counts:
        col_chart1, col_chart2 = st.columns(2)
        
        with col_chart1:
            # Gr√°fico de barras
            fig_bar = px.bar(
                x=list(pattern_counts.keys()),
                y=list(pattern_counts.values()),
                title="Distribuci√≥n por Tipo de Patr√≥n",
                labels={'x': 'Tipo de Patr√≥n', 'y': 'Cantidad'},
                color=list(pattern_counts.values()),
                color_continuous_scale='viridis'
            )
            fig_bar.update_layout(height=400)
            st.plotly_chart(fig_bar, use_container_width=True)
        
        with col_chart2:
            # Gr√°fico de pastel
            fig_pie = px.pie(
                values=list(pattern_counts.values()),
                names=list(pattern_counts.keys()),
                title="Proporci√≥n de Patrones"
            )
            fig_pie.update_layout(height=400)
            st.plotly_chart(fig_pie, use_container_width=True)
    
    # Configuraci√≥n del dataset
    st.markdown("### ‚öôÔ∏è Configuraci√≥n del Dataset")
    
    col_config1, col_config2 = st.columns(2)
    
    with col_config1:
        dataset_name = st.text_input(
            "üìù Nombre del Dataset:",
            value=f"wyckoff_patterns_{datetime.now().strftime('%Y%m%d_%H%M')}",
            help="Nombre √∫nico para identificar este dataset"
        )
        
        include_uncertain = st.checkbox(
            "‚ùì Incluir patrones inciertos",
            value=False,
            help="Incluir tambi√©n los patrones marcados como inciertos"
        )
    
    with col_config2:
        min_quality = st.slider(
            "‚≠ê Calidad m√≠nima requerida:",
            min_value=1,
            max_value=5,
            value=3,
            help="Solo incluir patrones con esta calidad o superior"
        )
        
        min_confidence = st.slider(
            "üéØ Confianza m√≠nima del trader:",
            min_value=0.0,
            max_value=1.0,
            value=0.5,
            step=0.1,
            help="Solo incluir patrones con esta confianza o superior"
        )
    
    # Filtrar datos seg√∫n configuraci√≥n
    filtered_labels = {}
    for k, v in labeling_results.items():
        if v['status'] == 'valid' or (include_uncertain and v['status'] == 'uncertain'):
            if v['quality_score'] >= min_quality and v['trader_confidence'] >= min_confidence:
                filtered_labels[k] = v
    
    st.markdown(f"### üéØ Dataset Resultante: {len(filtered_labels)} muestras")
    
    if len(filtered_labels) == 0:
        st.warning("‚ö†Ô∏è No hay muestras que cumplan los criterios seleccionados. Ajusta los filtros.")
        return
    
    # Mostrar preview del dataset
    with st.expander("üëÄ Vista Previa del Dataset", expanded=False):
        preview_data = []
        for idx, (k, v) in enumerate(list(filtered_labels.items())[:10]):
            preview_data.append({
                'ID': k,
                'Tipo': v['corrected_type'].title(),
                'Calidad': v['quality_score'],
                'Confianza Trader': f"{v['trader_confidence']:.1%}",
                'Confianza IA': f"{v['original_pattern'].confidence:.1%}",
                'Precio': f"${v['original_pattern'].price:.2f}",
                'Fecha': v['original_pattern'].timestamp.strftime('%d/%m/%Y %H:%M'),
                'Notas': v['notes'][:50] + '...' if len(v['notes']) > 50 else v['notes']
            })
        
        if preview_data:
            df_preview = pd.DataFrame(preview_data)
            st.dataframe(df_preview, use_container_width=True)
            
            if len(filtered_labels) > 10:
                st.info(f"üìã Mostrando 10 de {len(filtered_labels)} muestras totales")
    
    # Botones de acci√≥n
    st.markdown("### üöÄ Acciones del Dataset")
    
    col_btn1, col_btn2, col_btn3 = st.columns(3)
    
    with col_btn1:
        if st.button("üíæ Crear Dataset", type="primary", use_container_width=True):
            try:
                # Crear dataset usando DatasetManager
                dataset_manager = DatasetManager()
                
                # Convertir etiquetas a LabeledSamples
                labeled_samples = []
                for k, v in filtered_labels.items():
                    sample = LabeledSample(
                        signal=v['original_pattern'],
                        label=v['corrected_type'],
                        confidence=v['trader_confidence'],
                        metadata={
                            'quality_score': v['quality_score'],
                            'notes': v['notes'],
                            'labeling_timestamp': v['timestamp'].isoformat(),
                            'ai_confidence': v['original_pattern'].confidence
                        }
                    )
                    labeled_samples.append(sample)
                
                # Crear dataset
                dataset_id = dataset_manager.create_dataset(
                    name=dataset_name,
                    samples=labeled_samples,
                    metadata={
                        'creation_method': 'manual_labeling',
                        'total_samples': len(labeled_samples),
                        'min_quality': min_quality,
                        'min_confidence': min_confidence,
                        'include_uncertain': include_uncertain
                    }
                )
                
                st.success(f"‚úÖ Dataset '{dataset_name}' creado exitosamente con ID: {dataset_id}")
                st.balloons()
                
            except Exception as e:
                st.error(f"‚ùå Error creando dataset: {e}")
    
    with col_btn2:
        if st.button("üì§ Exportar CSV", use_container_width=True):
            try:
                # Crear DataFrame para exportar
                export_data = []
                for k, v in filtered_labels.items():
                    export_data.append({
                        'pattern_id': k,
                        'pattern_type': v['corrected_type'],
                        'timestamp': v['original_pattern'].timestamp.isoformat(),
                        'price': v['original_pattern'].price,
                        'ai_confidence': v['original_pattern'].confidence,
                        'trader_confidence': v['trader_confidence'],
                        'quality_score': v['quality_score'],
                        'status': v['status'],
                        'notes': v['notes'],
                        'labeling_timestamp': v['timestamp'].isoformat()
                    })
                
                df_export = pd.DataFrame(export_data)
                csv = df_export.to_csv(index=False)
                
                st.download_button(
                    label="‚¨áÔ∏è Descargar CSV",
                    data=csv,
                    file_name=f"{dataset_name}.csv",
                    mime="text/csv",
                    use_container_width=True
                )
                
            except Exception as e:
                st.error(f"‚ùå Error exportando CSV: {e}")
    
    with col_btn3:
        if st.button("üìã Ver Datasets Existentes", use_container_width=True):
            show_existing_datasets()

def show_existing_datasets():
    """Muestra los datasets existentes en el sistema."""
    
    st.markdown("### üìö Datasets Existentes")
    
    try:
        dataset_manager = DatasetManager()
        datasets = dataset_manager.list_datasets()
        
        if not datasets:
            st.info("üì≠ No hay datasets creados a√∫n.")
            return
        
        # Mostrar datasets en una tabla
        dataset_data = []
        for dataset in datasets:
            dataset_data.append({
                'ID': dataset['dataset_id'],
                'Nombre': dataset['name'],
                'Muestras': dataset.get('sample_count', 'N/A'),
                'Fecha Creaci√≥n': dataset['creation_date'],
                'M√©todo': dataset.get('metadata', {}).get('creation_method', 'N/A')
            })
        
        df_datasets = pd.DataFrame(dataset_data)
        st.dataframe(df_datasets, use_container_width=True)
        
        # Selector para ver detalles
        if len(datasets) > 0:
            selected_dataset = st.selectbox(
                "üîç Ver detalles del dataset:",
                options=range(len(datasets)),
                format_func=lambda x: f"{datasets[x]['name']} ({datasets[x]['dataset_id']})"
            )
            
            if selected_dataset is not None:
                dataset = datasets[selected_dataset]
                
                st.markdown(f"#### üìä Detalles: {dataset['name']}")
                
                col_detail1, col_detail2 = st.columns(2)
                
                with col_detail1:
                    st.write(f"**ID:** {dataset['dataset_id']}")
                    st.write(f"**Nombre:** {dataset['name']}")
                    st.write(f"**Fecha:** {dataset['creation_date']}")
                
                with col_detail2:
                    st.write(f"**Muestras:** {dataset.get('sample_count', 'N/A')}")
                    metadata = dataset.get('metadata', {})
                    st.write(f"**M√©todo:** {metadata.get('creation_method', 'N/A')}")
                    st.write(f"**Calidad m√≠n:** {metadata.get('min_quality', 'N/A')}")
                
                # Bot√≥n para exportar dataset
                if st.button(f"üì§ Exportar {dataset['name']}", key=f"export_{dataset['dataset_id']}"):
                    try:
                        samples = dataset_manager.get_dataset_samples(dataset['dataset_id'])
                        
                        export_data = []
                        for sample in samples:
                            export_data.append({
                                'pattern_type': sample.label,
                                'timestamp': sample.signal.timestamp.isoformat(),
                                'price': sample.signal.price,
                                'confidence': sample.confidence,
                                'metadata': str(sample.metadata)
                            })
                        
                        df_export = pd.DataFrame(export_data)
                        csv = df_export.to_csv(index=False)
                        
                        st.download_button(
                            label=f"‚¨áÔ∏è Descargar {dataset['name']}.csv",
                            data=csv,
                            file_name=f"{dataset['name']}.csv",
                            mime="text/csv",
                            key=f"download_{dataset['dataset_id']}"
                        )
                        
                    except Exception as e:
                        st.error(f"‚ùå Error exportando dataset: {e}")
    
    except Exception as e:
        st.error(f"‚ùå Error cargando datasets: {e}")

def show_automatic_detection(data_manager, symbol, timeframe, days_back, min_confidence, max_signals):
    """Muestra la funcionalidad de detecci√≥n autom√°tica de patrones."""
    
    st.header("üîç Detecci√≥n Autom√°tica de Patrones Wyckoff")
    st.markdown("""
    Utiliza reglas heur√≠sticas avanzadas para detectar autom√°ticamente patrones 
    de acumulaci√≥n y distribuci√≥n seg√∫n la metodolog√≠a Wyckoff.
    """)
    
    if st.button("üöÄ Ejecutar Detecci√≥n", type="primary"):
        with st.spinner("Analizando datos y detectando patrones..."):
            try:
                # Inicializar componentes
                heuristic_engine = WyckoffHeuristicEngine()
                
                # Obtener datos
                end_time = datetime.now()
                start_time = end_time - timedelta(days=days_back)
                
                df = data_manager.get_data(
                    symbol=symbol,
                    interval=timeframe,
                    start_time=start_time,
                    end_time=end_time
                )
                
                if df.empty:
                    st.error("‚ùå No se pudieron obtener datos para el an√°lisis")
                    return
                
                # Detectar patrones
                signals = heuristic_engine.analyze_pattern(df)
                
                # Filtrar por confianza
                filtered_signals = [
                    s for s in signals 
                    if s.confidence >= min_confidence
                ][:max_signals]
                
                # Mostrar resultados
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric(
                        "Total Se√±ales",
                        len(signals),
                        delta=f"+{len(filtered_signals)} filtradas"
                    )
                
                with col2:
                    avg_confidence = np.mean([s.confidence for s in filtered_signals]) if filtered_signals else 0
                    st.metric(
                        "Confianza Promedio",
                        f"{avg_confidence:.2f}",
                        delta=f"Min: {min_confidence}"
                    )
                
                with col3:
                    st.metric(
                        "Per√≠odo Analizado",
                        f"{days_back} d√≠as",
                        delta=f"{len(df)} velas"
                    )
                
                if filtered_signals:
                    # Gr√°fico de precio con se√±ales
                    fig = create_price_chart_with_signals(df, filtered_signals)
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # Tabla de se√±ales
                    st.subheader("üìã Se√±ales Detectadas")
                    
                    signals_data = []
                    for signal in filtered_signals:
                        description = getattr(signal, 'description', 'Sin descripci√≥n')
                        signals_data.append({
                            "Timestamp": signal.timestamp.strftime("%Y-%m-%d %H:%M"),
                            "Fase": signal.phase.value,
                            "Precio": f"${signal.price:.2f}",
                            "Confianza": f"{signal.confidence:.2f}",
                            "Descripci√≥n": description[:50] + "..." if len(description) > 50 else description
                        })
                    
                    signals_df = pd.DataFrame(signals_data)
                    st.dataframe(signals_df, use_container_width=True)
                    
                    # Distribuci√≥n por fases
                    phase_counts = {}
                    for signal in filtered_signals:
                        phase = signal.phase.value
                        phase_counts[phase] = phase_counts.get(phase, 0) + 1
                    
                    if phase_counts:
                        st.subheader("üìä Distribuci√≥n por Fases")
                        
                        fig_pie = px.pie(
                            values=list(phase_counts.values()),
                            names=list(phase_counts.keys()),
                            title="Distribuci√≥n de Se√±ales por Fase Wyckoff"
                        )
                        st.plotly_chart(fig_pie, use_container_width=True)
                
                else:
                    st.warning(f"‚ö†Ô∏è No se encontraron se√±ales con confianza >= {min_confidence}")
                    
            except Exception as e:
                st.error(f"‚ùå Error en la detecci√≥n: {str(e)}")
                st.exception(e)

def show_scoring_system(data_manager, symbol, timeframe, days_back, min_confidence):
    """Muestra el sistema de puntuaci√≥n de se√±ales."""
    
    st.header("üìä Sistema de Puntuaci√≥n de Se√±ales")
    st.markdown("""
    Eval√∫a la calidad de las se√±ales detectadas mediante un sistema 
    multi-dimensional que considera m√∫ltiples factores t√©cnicos.
    """)
    
    if st.button("üìà Analizar y Puntuar", type="primary"):
        with st.spinner("Ejecutando an√°lisis de puntuaci√≥n..."):
            try:
                # Inicializar componentes
                heuristic_engine = WyckoffHeuristicEngine()
                scoring_system = WyckoffScoringSystem()
                
                # Obtener datos
                end_time = datetime.now()
                start_time = end_time - timedelta(days=days_back)
                
                df = data_manager.get_data(
                    symbol=symbol,
                    interval=timeframe,
                    start_time=start_time,
                    end_time=end_time
                )
                
                if df.empty:
                    st.error("‚ùå No se pudieron obtener datos")
                    return
                
                # Detectar se√±ales
                signals = heuristic_engine.analyze_pattern(df)
                filtered_signals = [s for s in signals if s.confidence >= min_confidence]
                
                if not filtered_signals:
                    st.warning("‚ö†Ô∏è No hay se√±ales para puntuar")
                    return
                
                # Puntuar se√±ales
                scored_signals = []
                for signal in filtered_signals[:10]:  # Limitar a 10 para rendimiento
                    try:
                        # Obtener ventana de datos
                        signal_idx = df[df.index <= signal.timestamp].index[-1]
                        signal_index = df.index.get_loc(signal_idx)
                        window_start = max(0, signal_index - 50)
                        window_end = min(len(df), signal_index + 50)
                        window_data = df.iloc[window_start:window_end]
                        
                        # Calcular puntuaci√≥n
                        score = scoring_system.score_signal(signal, window_data, signal_index - window_start)
                        scored_signals.append((signal, score))
                        
                    except Exception as e:
                        st.warning(f"Error puntuando se√±al: {e}")
                        continue
                
                if scored_signals:
                    # Mostrar m√©tricas generales
                    scores = [score for _, score in scored_signals]
                    
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric(
                            "Se√±ales Puntuadas",
                            len(scored_signals),
                            delta=f"de {len(filtered_signals)} total"
                        )
                    
                    with col2:
                        avg_score = np.mean([s.overall_score for s in scores])
                        st.metric(
                            "Puntuaci√≥n Promedio",
                            f"{avg_score:.2f}/5",
                            delta=f"Rango: {min([s.overall_score for s in scores]):.1f}-{max([s.overall_score for s in scores]):.1f}"
                        )
                    
                    with col3:
                        high_quality = len([s for s in scores if s.overall_score >= 4.0])
                        st.metric(
                            "Alta Calidad (‚â•4.0)",
                            high_quality,
                            delta=f"{(high_quality/len(scores)*100):.1f}%"
                        )
                    
                    # Tabla detallada de puntuaciones
                    st.subheader("üéØ An√°lisis Detallado de Puntuaciones")
                    
                    scoring_data = []
                    for signal, score in scored_signals:
                        scoring_data.append({
                            "Timestamp": signal.timestamp.strftime("%Y-%m-%d %H:%M"),
                            "Fase": signal.phase.value,
                            "Precio": f"${signal.price:.2f}",
                            "Puntuaci√≥n Total": f"{score.overall_score:.2f}/5",
                            "Categor√≠a": score.category,
                            "Volumen": f"{score.volume_score:.1f}",
                            "Momentum": f"{score.momentum_score:.1f}",
                            "Estructura": f"{score.structure_score:.1f}",
                            "Sugerencias": ", ".join(score.improvement_suggestions[:2])
                        })
                    
                    scoring_df = pd.DataFrame(scoring_data)
                    st.dataframe(scoring_df, use_container_width=True)
                    
                    # Gr√°fico de distribuci√≥n de puntuaciones
                    st.subheader("üìä Distribuci√≥n de Puntuaciones")
                    
                    fig_hist = px.histogram(
                        x=[s.overall_score for s in scores],
                        nbins=10,
                        title="Distribuci√≥n de Puntuaciones Generales",
                        labels={"x": "Puntuaci√≥n", "y": "Frecuencia"}
                    )
                    st.plotly_chart(fig_hist, use_container_width=True)
                
            except Exception as e:
                st.error(f"‚ùå Error en el sistema de puntuaci√≥n: {str(e)}")
                st.exception(e)

def show_dataset_management(data_manager):
    """Muestra la gesti√≥n de datasets etiquetados."""
    
    st.header("üíæ Gesti√≥n de Datasets Etiquetados")
    st.markdown("""
    Administra datasets de patrones Wyckoff etiquetados para entrenamiento 
    de modelos de machine learning.
    """)
    
    try:
        dataset_manager = DatasetManager()
        
        # Mostrar datasets existentes
        st.subheader("üìö Datasets Existentes")
        
        datasets = dataset_manager.list_datasets()
        
        if datasets:
            for dataset in datasets:
                with st.expander(f"üìä {dataset['name']} (ID: {dataset['dataset_id']})"):
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.write(f"**Descripci√≥n:** {dataset['description']}")
                        st.write(f"**Creado:** {dataset['creation_date']}")
                        st.write(f"**Sesiones:** {len(dataset.get('annotation_sessions', []))}")
                    
                    with col2:
                        # Obtener estad√≠sticas del dataset
                        try:
                            summary = dataset_manager.get_dataset_summary(dataset['dataset_id'])
                            if summary:
                                st.metric("Total Muestras", summary['total_samples'])
                                st.metric("Muestras V√°lidas", summary['valid_samples'])
                                st.metric("Calidad Promedio", f"{summary['average_quality_score']:.2f}/5")
                        except:
                            st.write("Estad√≠sticas no disponibles")
                    
                    # Botones de acci√≥n
                    col_btn1, col_btn2, col_btn3 = st.columns(3)
                    
                    with col_btn1:
                        if st.button(f"üì• Exportar", key=f"export_{dataset['id']}"):
                            try:
                                export_path = dataset_manager.export_dataset(
                                    dataset['id'], 
                                    format='csv'
                                )
                                st.success(f"‚úÖ Dataset exportado a: {export_path}")
                            except Exception as e:
                                st.error(f"‚ùå Error exportando: {e}")
                    
                    with col_btn2:
                        if st.button(f"ü§ñ Preparar ML", key=f"ml_{dataset['id']}"):
                            try:
                                (X_train, y_train), (X_test, y_test) = dataset_manager.get_training_data(dataset['id'])
                                st.success(f"‚úÖ Datos ML preparados: {X_train.shape[0]} muestras")
                                
                                # Mostrar informaci√≥n de las caracter√≠sticas
                                st.write(f"**Caracter√≠sticas:** {X_train.shape[1]}")
                                st.write(f"**Entrenamiento:** {X_train.shape[0]} muestras")
                                st.write(f"**Prueba:** {X_test.shape[0]} muestras")
                                
                            except Exception as e:
                                st.error(f"‚ùå Error preparando ML: {e}")
                    
                    with col_btn3:
                        if st.button(f"üóëÔ∏è Eliminar", key=f"delete_{dataset['id']}"):
                            if st.session_state.get(f"confirm_delete_{dataset['id']}", False):
                                try:
                                    dataset_manager.delete_dataset(dataset['id'])
                                    st.success("‚úÖ Dataset eliminado")
                                    st.rerun()
                                except Exception as e:
                                    st.error(f"‚ùå Error eliminando: {e}")
                            else:
                                st.session_state[f"confirm_delete_{dataset['id']}"] = True
                                st.warning("‚ö†Ô∏è Haz clic nuevamente para confirmar")
        else:
            st.info("üìù No hay datasets creados a√∫n. Usa el flujo integrado para crear uno.")
        
        # Estad√≠sticas generales
        st.subheader("üìà Estad√≠sticas Generales")
        
        total_datasets = len(datasets)
        total_samples = sum(dataset_manager.get_dataset_summary(d['id'])['total_samples'] 
                          for d in datasets 
                          if dataset_manager.get_dataset_summary(d['id']))
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Total Datasets", total_datasets)
        
        with col2:
            st.metric("Total Muestras", total_samples)
        
        with col3:
            avg_quality = 0
            if datasets:
                qualities = []
                for d in datasets:
                    summary = dataset_manager.get_dataset_summary(d['id'])
                    if summary and summary['average_quality_score']:
                        qualities.append(summary['average_quality_score'])
                avg_quality = np.mean(qualities) if qualities else 0
            
            st.metric("Calidad Promedio", f"{avg_quality:.2f}/5")
        
    except Exception as e:
        st.error(f"‚ùå Error en gesti√≥n de datasets: {str(e)}")
        st.exception(e)

def show_integrated_workflow(data_manager, symbol, timeframe, days_back):
    """Muestra el flujo de trabajo integrado completo."""
    
    st.header("üîÑ Flujo de Trabajo Integrado")
    st.markdown("""
    Ejecuta el proceso completo desde la detecci√≥n autom√°tica hasta la 
    preparaci√≥n de datos para machine learning.
    """)
    
    # Configuraci√≥n del flujo
    with st.expander("‚öôÔ∏è Configuraci√≥n del Flujo", expanded=True):
        col1, col2 = st.columns(2)
        
        with col1:
            dataset_name = st.text_input(
                "Nombre del Dataset",
                value=f"Dataset {symbol} {timeframe} {datetime.now().strftime('%Y%m%d')}"
            )
            
            min_confidence_flow = st.slider(
                "Confianza m√≠nima para incluir",
                min_value=0.1,
                max_value=1.0,
                value=0.6,
                step=0.1
            )
        
        with col2:
            dataset_description = st.text_area(
                "Descripci√≥n del Dataset",
                value=f"Dataset generado autom√°ticamente para {symbol} en timeframe {timeframe}"
            )
            
            max_samples = st.number_input(
                "M√°ximo de muestras",
                min_value=10,
                max_value=1000,
                value=100,
                step=10
            )
    
    if st.button("üöÄ Ejecutar Flujo Completo", type="primary", use_container_width=True):
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        try:
            # Paso 1: Inicializaci√≥n
            status_text.text("üîß Paso 1/5: Inicializando componentes...")
            progress_bar.progress(0.1)
            
            heuristic_engine = WyckoffHeuristicEngine()
            scoring_system = WyckoffScoringSystem()
            dataset_manager = DatasetManager()
            
            # Paso 2: Obtenci√≥n de datos
            status_text.text("üìä Paso 2/5: Obteniendo datos hist√≥ricos...")
            progress_bar.progress(0.2)
            
            end_time = datetime.now()
            start_time = end_time - timedelta(days=days_back)
            
            df = data_manager.get_data(
                symbol=symbol,
                interval=timeframe,
                start_time=start_time,
                end_time=end_time
            )
            
            if df.empty:
                st.error("‚ùå No se pudieron obtener datos")
                return
            
            st.success(f"‚úÖ Datos obtenidos: {len(df)} velas")
            
            # Paso 3: Detecci√≥n y puntuaci√≥n
            status_text.text("üîç Paso 3/5: Detectando y puntuando patrones...")
            progress_bar.progress(0.4)
            
            signals = heuristic_engine.analyze_pattern(df)
            filtered_signals = [s for s in signals if s.confidence >= min_confidence_flow][:max_samples]
            
            if not filtered_signals:
                st.warning("‚ö†Ô∏è No se encontraron se√±ales con la confianza especificada")
                return
            
            st.info(f"üéØ Se√±ales detectadas: {len(filtered_signals)}")
            
            # Puntuar se√±ales
            scored_samples = []
            for i, signal in enumerate(filtered_signals):
                try:
                    # Obtener ventana de datos
                    signal_idx = df[df.index <= signal.timestamp].index[-1]
                    signal_index = df.index.get_loc(signal_idx)
                    window_start = max(0, signal_index - 50)
                    window_end = min(len(df), signal_index + 50)
                    window_data = df.iloc[window_start:window_end]
                    
                    # Calcular puntuaci√≥n
                    score = scoring_system.score_signal(signal, window_data, signal_index - window_start)
                    
                    # Crear muestra etiquetada
                    sample = LabeledSample(
                        timestamp=signal.timestamp,
                        symbol=symbol,
                        timeframe=timeframe,
                        phase=signal.phase,
                        confidence=signal.confidence,
                        price=signal.price,
                        volume=window_data.loc[signal_idx, 'volume'] if signal_idx in window_data.index else 0,
                        features={
                            'reasoning': getattr(signal, 'description', 'Sin descripci√≥n'),
                            'volume_score': score.volume_score,
                            'momentum_score': score.momentum_score,
                            'structure_score': score.structure_score,
                            'overall_score': score.overall_score,
                            'category': score.category
                        }
                    )
                    
                    scored_samples.append(sample)
                    
                    # Actualizar progreso
                    progress = 0.4 + (0.3 * (i + 1) / len(filtered_signals))
                    progress_bar.progress(progress)
                    
                except Exception as e:
                    st.warning(f"Error procesando se√±al {i+1}: {e}")
                    continue
            
            if not scored_samples:
                st.error("‚ùå No se pudieron procesar las se√±ales")
                return
            
            # Paso 4: Crear dataset
            status_text.text("üíæ Paso 4/5: Creando dataset...")
            progress_bar.progress(0.8)
            
            # Crear sesi√≥n de anotaci√≥n
            session_data = {
                'session_id': f"auto_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                'symbol': symbol,
                'timeframe': timeframe,
                'start_time': start_time,
                'end_time': end_time,
                'samples': scored_samples,
                'metadata': {
                    'detection_method': 'automatic_heuristic',
                    'min_confidence': min_confidence_flow,
                    'total_signals_detected': len(signals),
                    'signals_included': len(scored_samples)
                }
            }
            
            dataset_manager.save_annotations(session_data)
            dataset_id = dataset_manager.create_dataset(
                name=dataset_name,
                description=dataset_description,
                annotation_sessions=[session_data['session_id']]
            )
            
            st.success(f"‚úÖ Dataset creado con ID: {dataset_id}")
            
            # Paso 5: Preparar para ML
            status_text.text("ü§ñ Paso 5/5: Preparando datos para ML...")
            progress_bar.progress(0.9)
            
            try:
                (X_train, y_train), (X_test, y_test) = dataset_manager.get_training_data(dataset_id)
                progress_bar.progress(1.0)
                
                # Mostrar resultados finales
                st.success("üéâ ¬°Flujo completo ejecutado exitosamente!")
                
                # M√©tricas finales
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("Muestras Procesadas", len(scored_samples))
                
                with col2:
                    avg_confidence = np.mean([s.confidence for s in scored_samples])
                    st.metric("Confianza Promedio", f"{avg_confidence:.2f}")
                
                with col3:
                    st.metric("Datos Entrenamiento", X_train.shape[0])
                
                with col4:
                    st.metric("Datos Prueba", X_test.shape[0])
                
                # Resumen del dataset
                summary = dataset_manager.get_dataset_summary(dataset_id)
                if summary:
                    st.subheader("üìä Resumen del Dataset Creado")
                    
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric("Total Muestras", summary['total_samples'])
                    
                    with col2:
                        st.metric("Muestras V√°lidas", summary['valid_samples'])
                    
                    with col3:
                        st.metric("Calidad Promedio", f"{summary['average_quality_score']:.2f}/5")
                
                # Informaci√≥n adicional
                with st.expander("‚ÑπÔ∏è Informaci√≥n del Dataset"):
                    st.write(f"**ID del Dataset:** {dataset_id}")
                    st.write(f"**Nombre:** {dataset_name}")
                    st.write(f"**Descripci√≥n:** {dataset_description}")
                    st.write(f"**S√≠mbolo:** {symbol}")
                    st.write(f"**Timeframe:** {timeframe}")
                    st.write(f"**Per√≠odo:** {start_time.strftime('%Y-%m-%d')} a {end_time.strftime('%Y-%m-%d')}")
                    st.write(f"**Caracter√≠sticas ML:** {X_train.shape[1]}")
                
            except Exception as e:
                st.error(f"‚ùå Error preparando datos ML: {e}")
                st.info("üí° El dataset se cre√≥ correctamente, pero hubo un problema preparando los datos para ML")
            
        except Exception as e:
            st.error(f"‚ùå Error en el flujo integrado: {str(e)}")
            st.exception(e)
        
        finally:
            progress_bar.empty()
            status_text.empty()

def create_price_chart_with_signals(df, signals):
    """Crea un gr√°fico de precio con las se√±ales detectadas."""
    
    fig = make_subplots(
        rows=2, cols=1,
        shared_xaxes=True,
        vertical_spacing=0.1,
        subplot_titles=('Precio con Se√±ales Wyckoff', 'Volumen'),
        row_width=[0.7, 0.3]
    )
    
    # Gr√°fico de velas
    fig.add_trace(
        go.Candlestick(
            x=df.index,
            open=df['open'],
            high=df['high'],
            low=df['low'],
            close=df['close'],
            name="Precio"
        ),
        row=1, col=1
    )
    
    # A√±adir se√±ales
    colors = {
        'Acumulaci√≥n': 'green',
        'Distribuci√≥n': 'red',
        'Re-acumulaci√≥n': 'blue',
        'Re-distribuci√≥n': 'orange'
    }
    
    for signal in signals:
        color = colors.get(signal.phase.value, 'purple')
        
        fig.add_trace(
            go.Scatter(
                x=[signal.timestamp],
                y=[signal.price],
                mode='markers',
                marker=dict(
                    symbol='triangle-up' if 'acumulaci√≥n' in signal.phase.value.lower() else 'triangle-down',
                    size=15,
                    color=color,
                    line=dict(width=2, color='white')
                ),
                name=f"{signal.phase.value} ({signal.confidence:.2f})",
                hovertemplate=f"<b>{signal.phase.value}</b><br>" +
                             f"Precio: ${signal.price:.2f}<br>" +
                             f"Confianza: {signal.confidence:.2f}<br>" +
                             f"Descripci√≥n: {signal.description}<br>" +
                             "<extra></extra>"
            ),
            row=1, col=1
        )
    
    # Gr√°fico de volumen
    fig.add_trace(
        go.Bar(
            x=df.index,
            y=df['volume'],
            name="Volumen",
            marker_color='lightblue',
            opacity=0.7
        ),
        row=2, col=1
    )
    
    fig.update_layout(
        title="An√°lisis de Patrones Wyckoff",
        xaxis_title="Tiempo",
        yaxis_title="Precio",
        height=800,
        showlegend=True
    )
    
    fig.update_xaxes(rangeslider_visible=False)
    
    return fig